{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前置需要的依赖和变量&语义相似度计算\n",
    "\n",
    "from tfidf_cos import sentence_depart,get_wipe_stop_words_text_list,merge_two_text,create_two_text_vector,cal_tf,cal_idf,cal_tf_idf,cal_cosine_similarity\n",
    "import json\n",
    "\n",
    "def get_cosine_similarity(original_text1,original_text2):\n",
    "    # 两个文本去除停用词，并提取成词汇数组\n",
    "    text1=sentence_depart(original_text1)\n",
    "    text1=get_wipe_stop_words_text_list(text1)\n",
    "    # print(text1)\n",
    "    text2=sentence_depart(original_text2)\n",
    "    text2=get_wipe_stop_words_text_list(original_text2)\n",
    "    # print(text2)\n",
    "\n",
    "    # 创建词汇列表\n",
    "    vocabulary = merge_two_text(text1,text2)\n",
    "    # print(vocabulary)\n",
    "\n",
    "    # 利用词汇列表对两个文本创建向量矩阵\n",
    "    arr1,arr2 = create_two_text_vector(text1,text2,vocabulary)\n",
    "    # print(arr1,arr2)\n",
    "\n",
    "    # TF词频计算\n",
    "    tf1, tf2 = cal_tf(arr1,arr2)\n",
    "    # print(tf1,tf2)\n",
    "\n",
    "    # IDF逆文档频率计算\n",
    "    idf1, idf2 = cal_idf(text1,text2,vocabulary)\n",
    "    # print(idf1,idf2)\n",
    "\n",
    "    # TF-IDF词频-逆文档频率计算\n",
    "    tf_idf1 = cal_tf_idf(tf1,idf1)\n",
    "    tf_idf2 = cal_tf_idf(tf2,idf2)\n",
    "    # print(tf_idf1,tf_idf2)\n",
    "\n",
    "    # 余弦相似度计算\n",
    "    cos = cal_cosine_similarity(tf_idf1,tf_idf2)\n",
    "    # print(cos)\n",
    "    return cos\n",
    "\n",
    "base_atom_response_file=\"/home/w1nd/darkword/1darkword/model_eval/data/responses/base_atom_response.json\"\n",
    "lora_atom_response_file=\"/home/w1nd/darkword/1darkword/model_eval/data/responses/lora_atom_response.json\"\n",
    "lora_baichuan2_response_file=\"/home/w1nd/darkword/1darkword/model_eval/data/responses/lora_baichuan2_response.json\"\n",
    "lora_chatglm3_response_file=\"/home/w1nd/darkword/1darkword/model_eval/data/responses/lora_chatglm3_response.json\"\n",
    "\n",
    "# base_vs_lora_output_file\n",
    "base_atom_vs_lora_atom_file=\"/home/w1nd/darkword/1darkword/model_eval/data/base_winner/base_atom_vs_lora_atom.json\"\n",
    "base_atom_vs_lora_baichuan2_file=\"/home/w1nd/darkword/1darkword/model_eval/data/base_winner/base_atom_vs_lora_baichuan2.json\"\n",
    "base_atom_vs_lora_chatglm3_file=\"/home/w1nd/darkword/1darkword/model_eval/data/base_winner/base_atom_vs_lora_chatglm3.json\"\n",
    "\n",
    "# lora_vs_lora_output_file\n",
    "lora_atom_vs_lora_baichuan2_file = \"/home/w1nd/darkword/1darkword/model_eval/data/lora_winner/lora_atom_vs_lora_baichuan2.json\"\n",
    "lora_atom_vs_lora_chatglm3_file = \"/home/w1nd/darkword/1darkword/model_eval/data/lora_winner/lora_atom_vs_lora_chatglm3.json\"\n",
    "lora_baichuan2_vs_lora_chatglm3_file = \"/home/w1nd/darkword/1darkword/model_eval/data/lora_winner/lora_baichuan2_vs_lora_chatglm3.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行此模块前，需要运行第一个模块\n",
    "# base_atom和lora_darkword评估对比\n",
    "\n",
    "def base_and_lora_eval(base_file,lora_file,choice,output_file):\n",
    "    with open(base_file,\"r\",encoding=\"utf-8\") as basefile:\n",
    "        base_responses = json.load(basefile)\n",
    "    basefile.close()\n",
    "    with open(lora_file,\"r\",encoding=\"utf-8\") as lorafile:\n",
    "        lora_responses = json.load(lorafile)\n",
    "    lorafile.close()\n",
    "    with open(output_file,\"wt\",encoding=\"utf-8\") as output:\n",
    "        for one_base_response,one_lora_response in zip(base_responses,lora_responses):\n",
    "            # base_vs_atom\n",
    "            if choice == 1:\n",
    "                one_result={\"model_a\":\"atom_base\",\"model_b\":\"atom_lora\"}\n",
    "                text0 = one_base_response[\"question\"]\n",
    "                text1 = one_base_response[\"standard_answer\"]\n",
    "                text2 = one_base_response[\"atom_base_response\"]\n",
    "                text3 = one_lora_response[\"atom_lora_response\"]\n",
    "                text=[text0,text1,text2,text3]\n",
    "                cos1 = get_cosine_similarity(text1,text2)\n",
    "                cos2 = get_cosine_similarity(text1,text3)\n",
    "                # print(cos1,cos2)\n",
    "                winner = judge_winner(text,cos1,cos2)\n",
    "                one_result[\"winner\"] = winner\n",
    "                output.write(json.dumps(one_result,ensure_ascii=False)+\"\\n\")\n",
    "            # base_vs_baichuan2\n",
    "            elif choice == 2:\n",
    "                one_result={\"model_a\":\"atom_base\",\"model_b\":\"baichuan2_lora\"}\n",
    "                text0 = one_base_response[\"question\"]\n",
    "                text1 = one_base_response[\"standard_answer\"]\n",
    "                text2 = one_base_response[\"atom_base_response\"]\n",
    "                text3 = one_lora_response[\"baichuan2_lora_response\"]\n",
    "                text=[text0,text1,text2,text3]\n",
    "                cos1 = get_cosine_similarity(text1,text2)\n",
    "                cos2 = get_cosine_similarity(text1,text3)\n",
    "                # print(cos1,cos2)\n",
    "                winner = judge_winner(text,cos1,cos2)\n",
    "                one_result[\"winner\"] = winner\n",
    "                output.write(json.dumps(one_result,ensure_ascii=False)+\"\\n\")\n",
    "            # base_vs_chatglm3\n",
    "            elif choice == 3:\n",
    "                one_result={\"model_a\":\"atom_base\",\"model_b\":\"chatglm3_lora\"}\n",
    "                text0 = one_base_response[\"question\"]\n",
    "                text1 = one_base_response[\"standard_answer\"]\n",
    "                text2 = one_base_response[\"atom_base_response\"]\n",
    "                text3 = one_lora_response[\"chatglm3_lora_response\"]\n",
    "                text=[text0,text1,text2,text3]\n",
    "                cos1 = get_cosine_similarity(text1,text2)\n",
    "                cos2 = get_cosine_similarity(text1,text3)\n",
    "                # print(cos1,cos2)\n",
    "                winner = judge_winner(text,cos1,cos2)\n",
    "                one_result[\"winner\"] = winner\n",
    "                output.write(json.dumps(one_result,ensure_ascii=False)+\"\\n\")\n",
    "            # baichuan2_vs_chatglm3\n",
    "            else:\n",
    "                one_result={\"model_a\":\"baichuan2_lora\",\"model_b\":\"chatglm3_lora\"}\n",
    "                text0 = one_base_response[\"question\"]\n",
    "                text1 = one_base_response[\"standard_answer\"]\n",
    "                text2 = one_base_response[\"baichuan2_lora_response\"]\n",
    "                text3 = one_lora_response[\"chatglm3_lora_response\"]\n",
    "                text=[text0,text1,text2,text3]\n",
    "                cos1 = get_cosine_similarity(text1,text2)\n",
    "                cos2 = get_cosine_similarity(text1,text3)\n",
    "                # print(cos1,cos2)\n",
    "                winner = judge_winner(text,cos1,cos2)\n",
    "                one_result[\"winner\"] = winner\n",
    "                output.write(json.dumps(one_result,ensure_ascii=False)+\"\\n\")\n",
    "    output.close()\n",
    "\n",
    "\n",
    "# 这里设个阈值之类的就好了\n",
    "def judge_winner(text,cos1,cos2):\n",
    "    winner_a=\"model_a\"\n",
    "    winner_b=\"model_b\"\n",
    "    tie=\"tie\"\n",
    "    if cos1 == cos2:\n",
    "        return tie\n",
    "    elif cos1 >= 0.8 and cos2 >= 0.8:\n",
    "        if abs(cos1 - cos2) <= 0.1:\n",
    "            return tie\n",
    "        elif cos1 > cos2:\n",
    "            return winner_a\n",
    "        else:\n",
    "            return winner_b\n",
    "    elif cos1 >= 0.8:\n",
    "        return winner_a\n",
    "    elif cos2 >= 0.8:\n",
    "        return winner_b\n",
    "    elif cos1 > 0.2 or cos2 > 0.2:\n",
    "        if abs(cos1 - cos2) > 0.1:\n",
    "            if cos1 > cos2:\n",
    "                return winner_a\n",
    "            else:\n",
    "                return winner_b\n",
    "        else:\n",
    "            return tie\n",
    "    else:\n",
    "        return tie\n",
    "\n",
    "\n",
    "# 1.base_atom_vs_lora_atom\n",
    "base_and_lora_eval(base_atom_response_file,lora_atom_response_file,1,base_atom_vs_lora_atom_file)\n",
    "\n",
    "# 2.base_atom_vs_lora_baichuan2\n",
    "base_and_lora_eval(base_atom_response_file,lora_baichuan2_response_file,2,base_atom_vs_lora_baichuan2_file)\n",
    "\n",
    "# 3.base_atom_vs_lora_chatglm3\n",
    "base_and_lora_eval(base_atom_response_file,lora_chatglm3_response_file,3,base_atom_vs_lora_chatglm3_file)\n",
    "\n",
    "# 4.lora_baichuan2_vs_lora_chatglm3\n",
    "# base_and_lora_eval(lora_baichuan2_response_file,lora_chatglm3_response_file,4,test_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行此模块前，需要运行第一个模块\n",
    "# darkword_lora_model内部之间的评估\n",
    "\n",
    "def judge_winner(cos1,cos2):\n",
    "    winner_a=\"model_a\"\n",
    "    winner_b=\"model_b\"\n",
    "    tie=\"tie\"\n",
    "    if cos1 >= 0.8 or cos2 >= 0.8:\n",
    "        if abs(cos1-cos2) < 0.1:\n",
    "            return tie\n",
    "        elif cos1 > cos2:\n",
    "            return winner_a\n",
    "        else:\n",
    "            return winner_b\n",
    "    else:\n",
    "        if cos1 > cos2:\n",
    "            return winner_a\n",
    "        elif cos2 > cos1:\n",
    "            return winner_b\n",
    "    return tie\n",
    "\n",
    "# 这个其实是通用的生成语义相似度，然后比较输赢的函数，不管是哪两个模型都可以用！\n",
    "def lora_and_lora_eval(model_a_file,model_b_file,output_file):\n",
    "    with open(model_a_file,\"r\",encoding=\"utf-8\") as filea:\n",
    "        model_a_responses = json.load(filea)\n",
    "    filea.close()\n",
    "    with open(model_b_file,\"r\",encoding=\"utf-8\") as fileb:\n",
    "        model_b_responses = json.load(fileb)\n",
    "    fileb.close()\n",
    "    with open(output_file,\"wt\",encoding=\"utf-8\") as output:\n",
    "        for one_model_a_response, one_model_b_response in zip(model_a_responses,model_b_responses):\n",
    "            model_a_key = list(one_model_a_response.keys())[2]\n",
    "            model_b_key = list(one_model_b_response.keys())[2]\n",
    "            one_result = {\"model_a\":model_a_key.replace(\"_response\",\"\"),\"model_b\":model_b_key.replace(\"_response\",\"\")}\n",
    "            text0 = one_model_a_response[\"question\"]\n",
    "            text1 = one_model_a_response[\"standard_answer\"]\n",
    "            text2 = one_model_a_response[model_a_key]\n",
    "            text3 = one_model_b_response[model_b_key]\n",
    "            cos1 = get_cosine_similarity(text1,text2)\n",
    "            cos2 = get_cosine_similarity(text1,text3)\n",
    "            # print(cos1,cos2)\n",
    "            winner = judge_winner(cos1,cos2)\n",
    "            one_result[\"winner\"] = winner\n",
    "            output.write(json.dumps(one_result,ensure_ascii=False)+\"\\n\")\n",
    "    output.close\n",
    "\n",
    "\n",
    "# 1. lora_atom_vs_lora_baichuan2\n",
    "lora_and_lora_eval(lora_atom_response_file,lora_baichuan2_response_file,lora_atom_vs_lora_baichuan2_file)\n",
    "# 2. lora_atom_vs_lora_chatglm3\n",
    "lora_and_lora_eval(lora_atom_response_file,lora_chatglm3_response_file,lora_atom_vs_lora_chatglm3_file)\n",
    "# 3. lora_baichuan2_vs_lora_chatglm3\n",
    "lora_and_lora_eval(lora_baichuan2_response_file,lora_chatglm3_response_file,lora_baichuan2_vs_lora_chatglm3_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
